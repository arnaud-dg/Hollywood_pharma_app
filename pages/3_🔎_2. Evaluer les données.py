import os
import sys
import base64
import hashlib
import random
from io import BytesIO
from PIL import Image
from PIL.ExifTags import TAGS
import cv2
import numpy as np
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import streamlit as st
import matplotlib.pyplot as plt
import seaborn as sns
from streamlit.components.v1 import html
import base64
import re

# Ajout du chemin racine au path pour pouvoir importer utils et config
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
import config
from utils import load_data
from utils_s3 import get_s3_client, get_bucket_name, read_image_from_s3, list_s3_files

# Configuration de la page
st.set_page_config(page_title="Dataset", page_icon="üìä", layout="wide")

# Charger le logo en base64 (local)
def get_base64_of_bin_file(bin_file):
    with open(bin_file, 'rb') as f:
        data = f.read()
    return base64.b64encode(data).decode()

logo_base64 = get_base64_of_bin_file("assets/images/a3p.png")

st.markdown(
    f"""
    <style>
        [data-testid="stSidebarNav"]::before {{
            content: "";
            display: block;
            margin: 0 auto 20px auto;
            height: 200px;
            width: 250px;
            background-image: url("data:image/png;base64,{logo_base64}");
            background-repeat: no-repeat;
            background-size: contain;
            background-position: center;
        }}
    </style>
    """,
    unsafe_allow_html=True
)

# Dropdown avec session_state
if "group_choice" not in st.session_state:
    st.session_state.group_choice = ""

group_choice = st.sidebar.selectbox(
    "S√©lectionner un groupe",
    options=["", "Grp1", "Grp2", "Grp3", "Grp4", "Grp5", "Grp6", "Grp7"],
    index=0 if st.session_state.group_choice == "" else ["", "Grp1", "Grp2", "Grp3", "Grp4", "Grp5", "Grp6", "Grp7"].index(st.session_state.group_choice),
    help="Veuillez choisir un groupe pour afficher le contenu des pages.",
    key="group_choice"
)
st.sidebar.markdown("---")

if st.session_state.group_choice == "":
    st.warning("‚ö†Ô∏è Veuillez s√©lectionner un groupe dans la barre lat√©rale pour continuer.")
    st.stop()

try:
    with open("assets/css/style.css") as f:
        st.markdown(f"<style>{f.read()}</style>", unsafe_allow_html=True)
except FileNotFoundError:
    pass

# Titre de la page
st.title("üîé 2. Evaluer la qualit√© d'un jeu de donn√©es")
st.markdown("**Objectifs p√©dagogiques**")
st.markdown("""
- Comprendre et r√©aliser **<span style="color:#7345FF"> l'importance de la qualit√© des donn√©es</span>**.
- Acqu√©rir une **<span style="color:#7345FF">d√©marche structur√©e d'√©valuation des risques</span>**.
""", unsafe_allow_html=True)

st.markdown("**Votre mission**")
st.markdown("""
- Les data scientists de votre √©quipe vous ont pr√©par√© un rapide outil pour explorer les caract√©ristiques du jeu de donn√©es.
- La base de donn√©e servant √† entra√Æner notre IA est constitu√©e d'environ 2.500 images
(Un √©chantillon de 100 images a √©t√© s√©lectionn√© pour simplifier la d√©monstration). 
Vous devez vous assurer que les donn√©es qui vont √™tre utilis√©es pour l'entra√Ænement et le test sont appropri√©es
- Gardez **<span style="color:#7345FF"> un oeil critique et utilisez votre bon sens</span>** pour parcourir le panel de 100 images √† la recherche 
**<span style="color:#7345FF">d'anomalies</span>**, de **<span style="color:#7345FF">biais</span>** ou **<span style="color:#7345FF">d'incoh√©rences</span>** qui pourraient impacter directement ou indirectement 
la performance de l'IA.
""", unsafe_allow_html=True)

# Fonctions utilitaires
def image_to_base64_from_bytes(img_bytes):
    """Convertit des bytes d'image en base64 pour l'affichage HTML"""
    try:
        return base64.b64encode(img_bytes).decode("utf-8")
    except Exception as e:
        st.error(f"Erreur lors de la conversion de l'image: {e}")
        return None

def extract_image_metadata(img_bytes):
    """Extrait les m√©tadonn√©es d'une image depuis des bytes"""
    try:
        # Convertir bytes en array numpy
        nparr = np.frombuffer(img_bytes, np.uint8)
        img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        
        if img is None:
            return None, None, None
        
        h, w = img.shape[:2]
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        intensity = round(np.mean(gray), 2)
        return w, h, intensity
    except Exception as e:
        st.error(f"Erreur lors de l'extraction des m√©tadonn√©es: {e}")
        return None, None, None

def get_exif_metadata(img_bytes):
    """Extrait les m√©tadonn√©es EXIF d'une image"""
    try:
        image = Image.open(BytesIO(img_bytes))
        exif_data = image._getexif()
        metadata = {}
        if exif_data:
            for tag_id, value in exif_data.items():
                tag = TAGS.get(tag_id, tag_id)
                metadata[tag] = value
        return {
            "Auteur": metadata.get("Artist", "NA"),
            "Date EXIF": metadata.get("DateTimeOriginal", "NA")
        }
    except Exception:
        return {
            "Auteur": "NA",
            "Date EXIF": "NA"
        }

def get_file_hash(content_bytes, algo='sha256'):
    """Calcule le hash d'un fichier depuis bytes"""
    try:
        hash_func = hashlib.sha256() if algo == 'sha256' else hashlib.md5()
        hash_func.update(content_bytes)
        return hash_func.hexdigest()
    except Exception as e:
        st.error(f"Erreur lors du calcul du hash: {e}")
        return "NA"

@st.cache_data
def load_image_dataset_from_s3(s3_prefix="data/dataset_analyze"):
    """Charge et analyse le jeu de donn√©es d'images depuis S3"""
    
    image_data = []
    
    with st.spinner("Chargement et analyse des images depuis S3..."):
        # Lister tous les fichiers images dans le pr√©fixe
        all_files = list_s3_files(prefix=s3_prefix)
        image_files = [f for f in all_files if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
        
        if not image_files:
            st.error(f"Aucune image trouv√©e dans s3://{get_bucket_name()}/{s3_prefix}")
            return None
        
        progress_bar = st.progress(0)
        total_images = len(image_files)
        
        for idx, s3_key in enumerate(image_files):
            progress_bar.progress((idx + 1) / total_images)
            
            # Extraire les informations du chemin
            relative_path = s3_key.replace(s3_prefix + "/", "")
            parts = relative_path.split("/")
            
            label = parts[0] if len(parts) > 0 else "NA"
            defect_type = parts[1] if label == "Defect" and len(parts) > 1 else "NA"
            file_name = parts[-1]
            
            # Lire l'image depuis S3
            img_bytes_io = read_image_from_s3(s3_key)
            if not img_bytes_io:
                continue
            
            img_bytes = img_bytes_io.read()
            
            # M√©tadonn√©es
            w, h, intensity = extract_image_metadata(img_bytes)
            img_base64 = image_to_base64_from_bytes(img_bytes)
            img_tag = f'<img src="data:image/jpeg;base64,{img_base64}" width="150" style="border-radius: 5px;"/>' if img_base64 else "Image non disponible"
            
            metadata = get_exif_metadata(img_bytes)
            file_hash = get_file_hash(img_bytes)
            
            image_data.append({
                "Chemin S3": s3_key,
                "Nom fichier": file_name,
                "Image": img_tag,
                "Nature": label,
                "Type de d√©faut": defect_type,
                "Largeur (px)": w,
                "Hauteur (px)": h,
                "Luminosit√© moyenne": intensity,
                "Auteur": metadata["Auteur"],
                "Date de cr√©ation": metadata["Date EXIF"],
                "Hash (SHA-256)": file_hash
            })
        
        progress_bar.empty()
    
    if not image_data:
        st.error("Aucune donn√©e d'image n'a pu √™tre extraite.")
        return None
    
    # Cr√©ation du DataFrame
    df = pd.DataFrame(image_data)
    
    # Renommer la colonne
    df.rename(columns={"Nom fichier": "Index"}, inplace=True)
    
    # S√©lectionner 3 indices al√©atoires pour garder des valeurs NA
    indices_exceptions = random.sample(range(len(df)), min(3, len(df)))
    
    # Remplacer les NA sauf pour les exceptions
    for i in range(len(df)):
        if i not in indices_exceptions:
            if df.loc[i, "Auteur"] == "NA":
                df.loc[i, "Auteur"] = "JPL"
            if df.loc[i, "Date de cr√©ation"] == "NA":
                df.loc[i, "Date de cr√©ation"] = "01/02/2025"
    
    # Cr√©er une colonne cat√©gorie
    df["Cat√©gorie"] = df.apply(
        lambda row: row["Nature"] if row["Nature"] == "Good" else f'Defects - {row["Type de d√©faut"]}',
        axis=1
    )
    
    return df

def create_interactive_table(df):
    """Cr√©e un tableau interactif avec itables"""
    import tempfile
    import os
    
    # S√©lectionner les colonnes √† afficher
    display_columns = [
        "Index", "Image", "Nature", "Type de d√©faut", "Largeur (px)", 
        "Hauteur (px)", "Luminosit√© moyenne", "Auteur", "Date de cr√©ation", "Hash (SHA-256)"
    ]
    
    df_display = df[display_columns].copy()
    
    # Cr√©er un fichier HTML temporaire avec itables
    with tempfile.NamedTemporaryFile(mode='w', suffix='.html', delete=False, encoding='utf-8') as f:
        # En-t√™te HTML avec les CDN n√©cessaires
        html_content = """
        <!DOCTYPE html>
        <html>
        <head>
            <meta charset="utf-8">
            <title>Tableau Interactif</title>
            <link rel="stylesheet" type="text/css" href="https://cdn.datatables.net/1.13.6/css/jquery.dataTables.min.css">
            <script type="text/javascript" charset="utf8" src="https://code.jquery.com/jquery-3.7.0.min.js"></script>
            <script type="text/javascript" charset="utf8" src="https://cdn.datatables.net/1.13.6/js/jquery.dataTables.min.js"></script>
            <style>
                body { font-family: Arial, sans-serif; margin: 20px; }
                table.dataTable { width: 100% !important; }
                .dataTables_wrapper { width: 100%; }
                img { 
                    max-width: 120px; 
                    height: auto; 
                    border-radius: 4px; 
                    transition: transform 0.3s ease, z-index 0.3s ease; 
                    cursor: zoom-in;
                }
                img:hover { 
                    transform: scale(4);
                    transform-origin: top left;
                    z-index: 9999;
                    position: relative; 
                }
                .dataTables_filter input { width: 300px; }
            </style>
        </head>
        <body>
        """
        
        # Convertir le DataFrame en HTML
        table_html = df_display.to_html(table_id="interactive_table", escape=False, index=False)
        
        # Script JavaScript pour initialiser DataTables
        script = """
        <script>
        $(document).ready(function() {
            $('#interactive_table').DataTable({
                "pageLength": 100,
                "lengthMenu": [25, 50, 100],
                "scrollX": true,
                "scrollY": "800px",
                "scrollCollapse": true,
                "columnDefs": [
                    { "width": "80px", "targets": 0 },
                    { "width": "140px", "targets": 1 },
                    { "width": "100px", "targets": [2, 3] },
                    { "width": "80px", "targets": [4, 5, 6] },
                    { "width": "100px", "targets": [7, 8] },
                    { "width": "200px", "targets": 9 }
                ],
                "language": {
                    "lengthMenu": "Afficher _MENU_ entr√©es",
                    "zeroRecords": "Aucun r√©sultat trouv√©",
                    "info": "Affichage de _START_ √† _END_ sur _TOTAL_ entr√©es",
                    "infoEmpty": "Affichage de 0 √† 0 sur 0 entr√©e",
                    "infoFiltered": "(filtr√© √† partir de _MAX_ entr√©es totales)",
                    "search": "Rechercher:",
                    "paginate": {
                        "first": "Premier",
                        "last": "Dernier",
                        "next": "Suivant",
                        "previous": "Pr√©c√©dent"
                    }
                }
            });
        });
        </script>
        </body>
        </html>
        """
        
        # √âcrire le contenu complet
        f.write(html_content + table_html + script)
        temp_file_path = f.name
    
    # Lire le contenu du fichier et l'afficher
    with open(temp_file_path, 'r', encoding='utf-8') as f:
        html_content = f.read()
    
    # Nettoyer le fichier temporaire
    os.unlink(temp_file_path)
    
    # Afficher le tableau dans Streamlit
    html(html_content, height=900, scrolling=True)

def display_sample_images(df):
    """Affiche des images √©chantillons par cat√©gorie"""
    if "Cat√©gorie" not in df.columns:
        return
    
    categories_samples = {
        'Good': "IMG_003.jpg",
        'Defects - Hole': "IMG_012.jpg",
        'Defects - Spot': "IMG_080.jpg",
        'Defects - Scratch': "IMG_006.jpg"
    }
    
    selected_images = []
    
    for cat, sample_name in categories_samples.items():
        matching_rows = df[df["Index"] == sample_name]
        if not matching_rows.empty:
            s3_key = matching_rows.iloc[0]["Chemin S3"]
            img_bytes_io = read_image_from_s3(s3_key)
            if img_bytes_io:
                try:
                    img = Image.open(img_bytes_io)
                    selected_images.append((cat, img))
                except Exception as e:
                    st.warning(f"Impossible de charger l'image pour la cat√©gorie {cat}: {e}")
    
    if selected_images:
        cols = st.columns(min(4, len(selected_images)))
        for i, (cat, img) in enumerate(selected_images):
            with cols[i % 4]:
                st.image(img, caption=cat, width='stretch')

def create_intensity_plot(df):
    """Cr√©e un histogramme de distribution de l'intensit√© moyenne"""
    if "Luminosit√© moyenne" not in df.columns:
        return

    nbins = 30
    values = df["Luminosit√© moyenne"].dropna().values
    bin_edges = np.histogram_bin_edges(values, bins=nbins)

    bin_indices = np.digitize(df["Luminosit√© moyenne"], bins=bin_edges, right=False) - 1
    df["Bin"] = bin_indices

    hover_map = {}
    for b in range(len(bin_edges)-1):
        files = df.loc[df["Bin"] == b, "Index"].tolist()
        if files:
            formatted_list = format_file_list(files, per_line=6)
            hover_map[b] = f"{formatted_list}<br>({len(files)} images)"
        else:
            hover_map[b] = "(0 image)"

    fig = px.histogram(
        df,
        x="Luminosit√© moyenne",
        nbins=nbins,
        title="Distribution de la luminosit√© des images",
        labels={"Luminosit√© moyenne": "Luminosit√© de l'image (0-255)", "count": "Nombre d'images"},
        color_discrete_sequence=["#1f77b4"]
    )

    for trace in fig.data:
        bin_ids = df["Bin"].unique()
        hover_texts = [hover_map.get(b, "") for b in sorted(bin_ids)]
        trace.hovertext = hover_texts
        trace.hovertemplate = "<b>Bin %{x}</b><br>Images:<br>%{hovertext}<extra></extra>"

    fig.update_layout(
        showlegend=False,
        height=400,
        margin=dict(l=20, r=20, t=40, b=20)
    )

    st.plotly_chart(fig, use_container_width=True)

def format_file_list(files, per_line=6):
    """Supprime les extensions et formate la liste"""
    clean_files = [re.sub(r'\.(jpg|jpeg|png)$', '', f, flags=re.IGNORECASE) for f in files]
    lines = []
    for i in range(0, len(clean_files), per_line):
        lines.append(", ".join(clean_files[i:i+per_line]))
    return "<br>".join(lines)

def create_class_distribution_plot(df):
    """Cr√©e un diagramme √† barres du nombre d'images par classe"""
    if "Cat√©gorie" not in df.columns:
        return

    counts = df["Cat√©gorie"].value_counts().reset_index()
    counts.columns = ["Cat√©gorie", "Nombre"]

    color_map = {
        "Good": "green",
        "Defects - Hole": "#FF4C4C",
        "Defects - Scratch": "#CC0000",
        "Defects - Spot": "#FF9999"
    }
    counts["Couleur"] = counts["Cat√©gorie"].map(color_map)

    hover_texts = []
    for cat in counts["Cat√©gorie"]:
        files = df[df["Cat√©gorie"] == cat]["Index"].tolist()
        formatted_list = format_file_list(files, per_line=6)
        hover_texts.append(f"{formatted_list}<br>({len(files)} images)")

    fig = go.Figure(
        data=[
            go.Bar(
                x=counts["Cat√©gorie"],
                y=counts["Nombre"],
                marker_color=counts["Couleur"],
                text=counts["Nombre"],
                textposition="auto",
                hovertext=hover_texts,
                hovertemplate="<b>%{x}</b><br>Images:<br>%{hovertext}<extra></extra>"
            )
        ]
    )

    fig.update_layout(
        title="Nombre d'images par classe",
        xaxis_title="Cat√©gorie",
        yaxis_title="Nombre d'images",
        height=400,
        margin=dict(l=20, r=20, t=40, b=20)
    )

    st.plotly_chart(fig, use_container_width=True)


# Chargement automatique des donn√©es
s3_prefix = "data/dataset_analyze"

# V√©rifier si les donn√©es sont charg√©es
if 'df' not in st.session_state:
    st.session_state['df'] = load_image_dataset_from_s3(s3_prefix)

# V√©rifier si les donn√©es sont charg√©es
if st.session_state['df'] is None:
    st.error(f"Impossible de charger les donn√©es depuis s3://{get_bucket_name()}/{s3_prefix}")
    st.markdown("""
    ### Instructions :
    1. Assurez-vous que le bucket S3 contient le dossier `data/dataset_analyze`
    2. Le dossier doit contenir des sous-dossiers avec vos images (ex: `Good/`, `Defect/`)
    3. Rechargez la page pour relancer l'analyse
    """)
else:
    df = st.session_state['df']

    if df is not None and not df.empty:

        st.subheader("üì∏ Rappel visuel des diff√©rentes cat√©gories")

        col1, col2 = st.columns(2)
        with col1:
            st.metric("Nombre total d'images", len(df))
        
        with col2:
            st.metric("Nombre de cat√©gories", df["Cat√©gorie"].nunique())

        display_sample_images(df)

        st.markdown("---")

        st.subheader("üìà Statistiques g√©n√©rales sur le panel d'images")
        
        col1, col2 = st.columns([1,1])
        with col1:
            create_class_distribution_plot(df)

        with col2:
            create_intensity_plot(df)
        
        st.subheader("üîç Tableau interactif des donn√©es")
        st.info("üí° Pour plus de facilit√© utilisez les fonctionnalit√©s du tableau : tri + recherche globale.")
        
        create_interactive_table(df)
        
        csv_data = df.drop("Image", axis=1).to_csv(index=False)
        st.download_button(
            label="üì• T√©l√©charger les donn√©es compl√®tes (CSV)",
            data=csv_data,
            file_name="analyse_images.csv",
            mime="text/csv"
        )
    else:
        st.error("Erreur lors du chargement des donn√©es. V√©rifiez le chemin et r√©essayez.")